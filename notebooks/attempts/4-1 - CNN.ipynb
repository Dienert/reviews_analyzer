{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/5%20-%20Multi-class%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "https://github.com/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb\n",
    "\n",
    "https://towardsdatascience.com/deep-learning-for-nlp-with-pytorch-and-torchtext-4f92d69052f\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "CUDARuntimeError",
     "evalue": "cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCUDARuntimeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\4-1 - CNN.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000001?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000001?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000001?line=5'>6</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000001?line=7'>8</a>\u001b[0m use_gpu \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000001?line=8'>9</a>\u001b[0m \u001b[39mif\u001b[39;00m use_gpu:\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=29'>30</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=30'>31</a>\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=31'>32</a>\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=35'>36</a>\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=36'>37</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=37'>38</a>\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=38'>39</a>\u001b[0m \n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=39'>40</a>\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=48'>49</a>\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=49'>50</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=50'>51</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=51'>52</a>\u001b[0m         name, vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/__init__.py?line=52'>53</a>\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:420\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=417'>418</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=418'>419</a>\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=419'>420</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=420'>421</a>\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=421'>422</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:453\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[1;34m(name, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=437'>438</a>\u001b[0m \u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=438'>439</a>\u001b[0m \n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=439'>440</a>\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=449'>450</a>\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=450'>451</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=451'>452</a>\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=452'>453</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\en_core_web_sm\\__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[1;34m(**overrides)\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/en_core_web_sm/__init__.py?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[1;32m---> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/en_core_web_sm/__init__.py?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moverrides)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:615\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[1;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=612'>613</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=613'>614</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=614'>615</a>\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=615'>616</a>\u001b[0m     data_path,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=616'>617</a>\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=617'>618</a>\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=618'>619</a>\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=619'>620</a>\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=620'>621</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=621'>622</a>\u001b[0m )\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:489\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[1;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=486'>487</a>\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=487'>488</a>\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(config, vocab\u001b[39m=\u001b[39mvocab, disable\u001b[39m=\u001b[39mdisable, exclude\u001b[39m=\u001b[39mexclude)\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=488'>489</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39;49mfrom_disk(model_path, exclude\u001b[39m=\u001b[39;49mexclude, overrides\u001b[39m=\u001b[39;49moverrides)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\language.py:2042\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[1;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2038'>2039</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2039'>2040</a>\u001b[0m     \u001b[39m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2040'>2041</a>\u001b[0m     exclude \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(exclude) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2041'>2042</a>\u001b[0m util\u001b[39m.\u001b[39;49mfrom_disk(path, deserializers, exclude)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2042'>2043</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m path  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2043'>2044</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_link_components()\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:1299\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1295'>1296</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1296'>1297</a>\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1297'>1298</a>\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1298'>1299</a>\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1299'>1300</a>\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\language.py:2018\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2015'>2016</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize_vocab\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2016'>2017</a>\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/language.py?line=2017'>2018</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mfrom_disk(path, exclude\u001b[39m=\u001b[39;49mexclude)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\vocab.pyx:460\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\vectors.pyx:616\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\util.py:1299\u001b[0m, in \u001b[0;36mfrom_disk\u001b[1;34m(path, readers, exclude)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1295'>1296</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1296'>1297</a>\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1297'>1298</a>\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1298'>1299</a>\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/spacy/util.py?line=1299'>1300</a>\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\spacy\\vectors.pyx:602\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk.load_vectors\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\cupy\\_io\\npz.py:71\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_io/npz.py?line=67'>68</a>\u001b[0m     obj \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mload(file, mmap_mode)\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_io/npz.py?line=69'>70</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, numpy\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m---> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_io/npz.py?line=70'>71</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m cupy\u001b[39m.\u001b[39;49marray(obj)\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_io/npz.py?line=71'>72</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, numpy\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39mnpyio\u001b[39m.\u001b[39mNpzFile):\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_io/npz.py?line=72'>73</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m NpzFile(obj)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\cupy\\_creation\\from_data.py:46\u001b[0m, in \u001b[0;36marray\u001b[1;34m(obj, dtype, copy, order, subok, ndmin)\u001b[0m\n\u001b[0;32m      <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39marray\u001b[39m(obj, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mK\u001b[39m\u001b[39m'\u001b[39m, subok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, ndmin\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m      <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=7'>8</a>\u001b[0m     \u001b[39m\"\"\"Creates an array on the current device.\u001b[39;00m\n\u001b[0;32m      <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=8'>9</a>\u001b[0m \n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=9'>10</a>\u001b[0m \u001b[39m    This function currently does not support the ``subok`` option.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=43'>44</a>\u001b[0m \n\u001b[0;32m     <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=44'>45</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/cupy/_creation/from_data.py?line=45'>46</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _core\u001b[39m.\u001b[39;49marray(obj, dtype, copy, order, subok, ndmin)\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2250\u001b[0m, in \u001b[0;36mcupy._core.core.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2271\u001b[0m, in \u001b[0;36mcupy._core.core.array\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\_core\\core.pyx:2420\u001b[0m, in \u001b[0;36mcupy._core.core._array_default\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\stream.pyx:306\u001b[0m, in \u001b[0;36mcupy.cuda.stream._BaseStream.record\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy\\cuda\\stream.pyx:125\u001b[0m, in \u001b[0;36mcupy.cuda.stream.Event.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy_backends\\cuda\\api\\runtime.pyx:875\u001b[0m, in \u001b[0;36mcupy_backends.cuda.api.runtime.eventCreateWithFlags\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mcupy_backends\\cuda\\api\\runtime.pyx:132\u001b[0m, in \u001b[0;36mcupy_backends.cuda.api.runtime.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCUDARuntimeError\u001b[0m: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import dataset\n",
    "from torch import nn, Tensor\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "  print(\"CUDA available.\\nPytorch set with GPU\")\n",
    "  DEVICE = torch.device(\"cuda\")\n",
    "  result = spacy.require_gpu()\n",
    "  print(\"Spacy set with GPU.\" if result else None)\n",
    "else:\n",
    "  print(\"CUDA not available. CPU processing\")\n",
    "  DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews_file):\n",
    "        self.df = pd.read_csv(reviews_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.df.iloc[idx, 0]\n",
    "        starts = self.df.iloc[idx, 1]\n",
    "        return starts,review \n",
    "\n",
    "    def review(self, idx):\n",
    "        return self.df.iloc[idx, 0]\n",
    "\n",
    "    def stars(self, idx):\n",
    "        return self.df.iloc[idx, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'final_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = ReviewsDataset(f'../dataset/{label_type}/train.csv')\n",
    "val_iter = ReviewsDataset(f'../dataset/{label_type}/train.csv')\n",
    "test_iter = ReviewsDataset(f'../dataset/{label_type}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cuddeterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for stars, review in data_iter:\n",
    "        yield tokenizer(review)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286, 12, 39, 266]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_iter = iter(train_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Four Stars. thought provoking')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(rows_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_iter = iter(yield_tokens(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['four', 'stars', '.', 'thought', 'provoking']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tokens_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8159"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_spacy = {}\n",
    "\n",
    "# for index,row in enumerate(iter(train_iter)):\n",
    "#     doc = nlp(row[0])\n",
    "#     sentences = doc.sents\n",
    "\n",
    "#     for sent in sentences:\n",
    "#         tokens = nlp(sent.text)\n",
    "\n",
    "#     for tkn in tokens:\n",
    "#         if tkn.text in vocab_spacy.keys():\n",
    "#             vocab_spacy[tkn.text] += 1\n",
    "#         else:\n",
    "#             vocab_spacy[tkn.text] = 1\n",
    "# len(vocab_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_spacy: 4653 (takes 5 min to process with GPU enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286, 12, 39, 266]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 48, 12, 8, 1586, 48, 18, 58, 6, 791]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('This one is a weird one for me to write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX = vocab(['<pad>'])[0]\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of batches for training\n",
    "train_batch_size = 64\n",
    "\n",
    "# Number of batches for validation. Use a larger value than training.\n",
    "# It helps speed up the validation process.\n",
    "valid_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([204,  70,   2,  ..., 580, 180,   2]), tensor([1, 0, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 2, 0, 2, 2,\n",
      "        1, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 1, 1, 2,\n",
      "        2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1]), tensor([   0,    5,   32,  108,  127,  135,  264,  350,  360,  438,  688,  719,\n",
      "         747,  796,  886,  917,  995, 1086, 1149, 1185, 1209, 1231, 1235, 1294,\n",
      "        1417, 1452, 1751, 1782, 1837, 1878, 1900, 1950, 2093, 2165, 2256, 2455,\n",
      "        2522, 2581, 2589, 2620, 2870, 2924, 2938, 2974, 3033, 3063, 3138, 3160,\n",
      "        3239, 3245, 3289, 3355, 3367, 3409, 3936, 4001, 4011, 4040, 4179, 4202,\n",
      "        4353, 4368, 4401, 4424]))\n"
     ]
    }
   ],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for (_label, _text) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "         text_list.append(processed_text)\n",
    "         offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return text_list.to(DEVICE), label_list.to(DEVICE), offsets.to(DEVICE)\n",
    "\n",
    "train_dataloader = DataLoader(train_iter, batch_size=train_batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_iter, batch_size=valid_batch_size, shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_iter, batch_size=valid_batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4495\n",
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "tt_iter = iter(train_dataloader)\n",
    "sample = next(tt_iter)\n",
    "print(len(sample[0]))\n",
    "print(len(sample[1]))\n",
    "print(len(sample[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, EmbeddingBag, ModuleList, Conv2d, Module, Linear, Dropout\n",
    "\n",
    "class CNN(Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        # self.embedding = Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim, sparse=True)\n",
    "        \n",
    "        self.convs = ModuleList([Conv2d(in_channels = 1, \n",
    "                                        out_channels = n_filters, \n",
    "                                        kernel_size = (fs, embedding_dim)) \n",
    "                            for fs in filter_sizes\n",
    "                            ])\n",
    "        \n",
    "        self.fc = Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = Dropout(dropout)\n",
    "        \n",
    "    # def forward(self, text):#, offsets):\n",
    "    def forward(self, text, offsets):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text, offsets)\n",
    "        # embedded = self.embedding(text)#, offsets)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "                \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import FastText\n",
    "# embedding = FastText('simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CharNGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import CharNGram\n",
    "# embedding_charngram = CharNGram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import GloVe\n",
    "# embedding_glove = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER = torch.nn.Embedding.from_pretrained(embedding.vectors,freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myvocab = vocab(EMBEDDING_LAYER.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER.stoi['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "# model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to use GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): EmbeddingBag(8159, 100, mode=mean)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    print(\"Trying to use GPU\")\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    torch.cuda.init()\n",
    "    cudnn.benchmark = True\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 937,103 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# criterion = nn.CrossEntropyLoss(    )\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_count = 0, 0\n",
    "    log_interval = 500\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "        total_count += label.size(0)\n",
    "        if idx % log_interval == 0 and idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                              total_acc/total_count))\n",
    "            total_acc, total_count = 0, 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_count = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\4-1 - CNN.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000048?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000048?line=15'>16</a>\u001b[0m     epoch_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000048?line=16'>17</a>\u001b[0m     train(train_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000048?line=17'>18</a>\u001b[0m     accu_val \u001b[39m=\u001b[39m evaluate(val_dataloader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000048?line=18'>19</a>\u001b[0m     \u001b[39mif\u001b[39;00m total_accu \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m total_accu \u001b[39m>\u001b[39m accu_val:\n",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\4-1 - CNN.ipynb Cell 48'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000047?line=5'>6</a>\u001b[0m log_interval \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000047?line=6'>7</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000047?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, (label, text, offsets) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000047?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/4-1%20-%20CNN.ipynb#ch0000047?line=10'>11</a>\u001b[0m     predicted_label \u001b[39m=\u001b[39m model(text, offsets)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:311\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=308'>309</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_iterator\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_BaseDataLoaderIter\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=309'>310</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=310'>311</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _SingleProcessDataLoaderIter(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:561\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=559'>560</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, loader):\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=560'>561</a>\u001b[0m     \u001b[39msuper\u001b[39;49m(_SingleProcessDataLoaderIter, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(loader)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=561'>562</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=562'>563</a>\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_workers \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:507\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=504'>505</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collate_fn \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mcollate_fn\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=505'>506</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_sampler)\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=506'>507</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_seed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mempty((), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64)\u001b[39m.\u001b[39;49mrandom_(generator\u001b[39m=\u001b[39;49mloader\u001b[39m.\u001b[39;49mgenerator)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=507'>508</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mpersistent_workers\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/utils/data/dataloader.py?line=508'>509</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "# Hyperparameters\n",
    "EPOCHS = 10 # epoch\n",
    "LR = 5  # learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "total_accu = None\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "num_train = int(len(train_dataset) * 0.95)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader)\n",
    "    accu_val = evaluate(val_dataloader)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 59)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d8aee86fee2b3ba25d32dc9f725c5d414dda3463734cf4a34eb13ce0a97930c"
  },
  "kernelspec": {
   "display_name": "PyTorch 1.8 (NGC 20.11/Python 3.6 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
