{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/text_sentiment_ngrams_tutorial.html\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\n",
    "\n",
    "https://github.com/pytorch/text/blob/master/examples/legacy_tutorial/migration_tutorial.ipynb\n",
    "\n",
    "https://towardsdatascience.com/deep-learning-for-nlp-with-pytorch-and-torchtext-4f92d69052f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available.\n",
      "Pytorch with GPU processing\n",
      "Spacy set with GPU \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import dataset\n",
    "from torch import nn, Tensor\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "  print(\"CUDA available.\\nPytorch with GPU processing\")\n",
    "  DEVICE = torch.device(\"cuda\")\n",
    "  result = spacy.require_gpu()\n",
    "  print(\"Spacy set with GPU \" if result else None)\n",
    "else:\n",
    "  print(\"CUDA not available. CPU processing\")\n",
    "  DEVICE = torch.device(\"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews_file):\n",
    "        self.df = pd.read_csv(reviews_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.df.iloc[idx, 0]\n",
    "        starts = self.df.iloc[idx, 1]\n",
    "        return review, starts\n",
    "\n",
    "    def review(self, idx):\n",
    "        return self.df.iloc[idx, 0]\n",
    "\n",
    "    def stars(self, idx):\n",
    "        return self.df.iloc[idx, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = 'final_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = ReviewsDataset(f'../dataset/{label_type}/train.csv')\n",
    "val_iter = ReviewsDataset(f'../dataset/{label_type}/train.csv')\n",
    "test_iter = ReviewsDataset(f'../dataset/{label_type}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for review, stars in data_iter:\n",
    "        yield tokenizer(review)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286, 12, 39, 266]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_iter = iter(train_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Four Stars. thought provoking', 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(rows_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_iter = iter(yield_tokens(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['four', 'stars', '.', 'thought', 'provoking']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tokens_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8159"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_spacy = {}\n",
    "\n",
    "# for index,row in enumerate(iter(train_iter)):\n",
    "#     doc = nlp(row[0])\n",
    "#     sentences = doc.sents\n",
    "\n",
    "#     for sent in sentences:\n",
    "#         tokens = nlp(sent.text)\n",
    "\n",
    "#     for tkn in tokens:\n",
    "#         if tkn.text in vocab_spacy.keys():\n",
    "#             vocab_spacy[tkn.text] += 1\n",
    "#         else:\n",
    "#             vocab_spacy[tkn.text] = 1\n",
    "# len(vocab_spacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_spacy: 4653 (takes 5 min to process with GPU enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[286, 12, 3, 39, 266]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('here is the an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 48, 12, 8, 1586, 48, 18, 58, 6, 791]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline('This one is a weird one for me to write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_IDX = vocab(['<pad>'])[0]\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of batches for training\n",
    "train_batch_size = 64\n",
    "\n",
    "# Number of batches for validation. Use a larger value than training.\n",
    "# It helps speed up the validation process.\n",
    "valid_batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def batchify(tensors: Tuple, batch_size: int) -> Tensor:\n",
    "#     \"\"\"Divides the data into bacthes separate sequences, removing extra elements\n",
    "#     that wouldn't cleanly fit.\n",
    "\n",
    "#     Args:\n",
    "#         data: Tensor, shape [N]\n",
    "#         bsz: int, batch size\n",
    "\n",
    "#     Returns:\n",
    "#         Tensor of shape [N // batch_size, batch_size]\n",
    "#     \"\"\"\n",
    "#     texts = tensors[0]\n",
    "#     labels = tensors[1]\n",
    "#     seq_len = texts.__len__() // batch_size\n",
    "#     texts = texts[:seq_len * batch_size]\n",
    "#     texts = texts.view(batch_size, seq_len).t().contiguous()\n",
    "\n",
    "#     seq_len = labels.__len__() // batch_size\n",
    "#     labels = labels[:seq_len * batch_size]\n",
    "#     labels = labels.view(batch_size, seq_len).t().contiguous()\n",
    "#     return texts.to(DEVICE), labels.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "#     \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    \n",
    "#     # [print(type(item[1])) for item in raw_text_iter]\n",
    "#     texts = [torch.tensor(text_pipeline(item[0]), dtype=torch.long) for item in raw_text_iter]\n",
    "#     labels = [torch.tensor(item[1], dtype=torch.long) for item in raw_text_iter]\n",
    "#     return torch.cat(tuple(filter(lambda t: t.numel() > 0, texts))), labelslabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iterator = batchify(data_process(training_data), train_batch_size) \n",
    "# val_iterator = batchify(data_process(valid_data), valid_batch_size)\n",
    "# test_iterator = batchify(data_process(test_data), valid_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "   label_list, text_list = [], []\n",
    "   for (_text, _label) in batch:\n",
    "         label_list.append(label_pipeline(_label))\n",
    "         processed_text = torch.tensor(text_pipeline(_text))\n",
    "         text_list.append(processed_text)\n",
    "   return pad_sequence(text_list, padding_value=PAD_IDX), torch.tensor(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 204,   24,   46,  ...,  351, 3299,  325],\n",
      "        [  70,   45,   96,  ...,   28,  334,  638],\n",
      "        [   2,    9,   21,  ...,    2,    7,   10],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]]), tensor([1, 0, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 2, 0, 2, 2,\n",
      "        1, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 1, 1, 2,\n",
      "        2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "train_list = list(train_iter)\n",
    "batch_size = train_batch_size \n",
    "\n",
    "def batch_sampler():\n",
    "    indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(train_list)]\n",
    "    random.shuffle(indices)\n",
    "    pooled_indices = []\n",
    "    # create pool of indices with similar lengths \n",
    "    for i in range(0, len(indices), batch_size * 100):\n",
    "        pooled_indices.extend(sorted(indices[i:i + batch_size * 100], key=lambda x: x[0]))\n",
    "\n",
    "    pooled_indices = [x[0] for x in pooled_indices]\n",
    "\n",
    "    # yield indices for current batch\n",
    "    for i in range(0, len(pooled_indices), batch_size):\n",
    "        yield pooled_indices[i:i + batch_size]\n",
    "\n",
    "bucket_dataloader = DataLoader(train_list, batch_sampler=batch_sampler(), collate_fn=collate_batch)\n",
    "\n",
    "print(next(iter(bucket_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(list(train_iter), batch_sampler=batch_sampler(), collate_fn=collate_batch)\n",
    "val_dataloader = DataLoader(list(val_iter), batch_sampler=batch_sampler(), collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(list(test_iter), batch_sampler=batch_sampler(), collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 204,   24,   46,  ...,  351, 3299,  325],\n",
      "        [  70,   45,   96,  ...,   28,  334,  638],\n",
      "        [   2,    9,   21,  ...,    2,    7,   10],\n",
      "        ...,\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [   1,    1,    1,  ...,    1,    1,    1]]), tensor([1, 0, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2, 2, 1, 1, 1, 2, 0, 2, 1, 2, 0, 2, 2,\n",
      "        1, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 0, 2, 2, 0, 1, 0, 2, 2, 2, 2, 1, 1, 2,\n",
      "        2, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.conv_0 = nn.Conv2d(in_channels = 100, \n",
    "                                out_channels = 16, \n",
    "                                kernel_size = (filter_sizes[0], embedding_dim))\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(in_channels = 16, \n",
    "                                out_channels = 32, \n",
    "                                kernel_size = (filter_sizes[1], embedding_dim))\n",
    "        \n",
    "        self.conv_2 = nn.Conv2d(in_channels = 32, \n",
    "                                out_channels = 16, \n",
    "                                kernel_size = (filter_sizes[2], embedding_dim))\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "                \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved_0 = F.relu(self.conv_0(embedded).squeeze(3))\n",
    "        # conved_1 = F.relu(self.conv_1(embedded).squeeze(3))\n",
    "        # conved_2 = F.relu(self.conv_2(embedded).squeeze(3))\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled_0 = F.max_pool1d(conved_0, conved_0.shape[2]).squeeze(2)\n",
    "        # pooled_1 = F.max_pool1d(conved_1, conved_1.shape[2]).squeeze(2)\n",
    "        # pooled_2 = F.max_pool1d(conved_2, conved_2.shape[2]).squeeze(2)\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat((pooled_0)#, pooled_1, pooled_2)\n",
    "                                    , dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1d(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv1d(in_channels = embedding_dim, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = fs)\n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        #embedded = [batch size, emb dim, sent len]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "            \n",
    "        #conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "        \n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import FastText\n",
    "# embedding = FastText('simple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CharNGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import CharNGram\n",
    "# embedding_charngram = CharNGram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import GloVe\n",
    "# embedding_glove = GloVe(name='6B', dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER = torch.nn.Embedding.from_pretrained(embedding.vectors,freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myvocab = vocab(EMBEDDING_LAYER.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_LAYER.stoi['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 3\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = embedding\n",
    "# embedding = embedding_charngram\n",
    "# embedding = embedding_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "# model = CNN1d(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to use GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(8159, 100, padding_idx=1)\n",
       "  (conv_0): Conv2d(100, 16, kernel_size=(3, 100), stride=(1, 1))\n",
       "  (conv_1): Conv2d(16, 32, kernel_size=(4, 100), stride=(1, 1))\n",
       "  (conv_2): Conv2d(32, 16, kernel_size=(5, 100), stride=(1, 1))\n",
       "  (fc): Linear(in_features=300, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_gpu:\n",
    "    print(\"Trying to use GPU\")\n",
    "    import torch.backends.cudnn as cudnn\n",
    "    torch.cuda.init()\n",
    "    cudnn.benchmark = True\n",
    "    model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,757,667 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "criterion = criterion.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch[0]).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch[1])\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch[1])\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            print(batch)\n",
    "            predictions = model(batch[0]).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch[1])\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch[1])\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'actual_batch_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 54'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000052?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000052?line=6'>7</a>\u001b[0m     start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000052?line=8'>9</a>\u001b[0m     train_loss, train_acc \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000052?line=9'>10</a>\u001b[0m     valid_loss, valid_acc \u001b[39m=\u001b[39m evaluate(model, val_dataloader, criterion)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000052?line=11'>12</a>\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 51'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000049?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m iterator:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000049?line=9'>10</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000049?line=11'>12</a>\u001b[0m     predictions \u001b[39m=\u001b[39m model(batch[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000049?line=13'>14</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(predictions, batch[\u001b[39m1\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000049?line=15'>16</a>\u001b[0m     acc \u001b[39m=\u001b[39m categorical_accuracy(predictions, batch[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'actual_batch_len'"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim,\n",
    "                 hidden, n_label, n_layers):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden,\n",
    "                            num_layers=n_layers,\n",
    "                            bidirectional=True,\n",
    "                            batch_first=True)#dropout=0.2\n",
    "        self.fc = nn.Linear(hidden * 2, n_label)\n",
    "    def forward(self, input, actual_batch_len):\n",
    "        embed_out = self.embed(input)\n",
    "        hidden = torch.zeros(self.n_layers * 2 ,\n",
    "                             input.shape[0], self.hidden)\n",
    "        cell = torch.zeros( self.n_layers * 2,\n",
    "                            input.shape[0], self.hidden)\n",
    "        pack_out = nn.utils.rnn.pack_padded_sequence(\n",
    "            embed_out, actual_batch_len,batch_first=True).to(device)\n",
    "        out_lstm, (hidden, cell) = self.lstm(pack_out,\n",
    "                                             (hidden, cell))#dropout\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]),dim=1)\n",
    "        out = self.fc(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN= 64\n",
    "NUM_LABEL = 4 # number of classes\n",
    "NUM_LAYERS = 2 \n",
    "model = SentimentClassifier(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN, NUM_LABEL, NUM_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    _, preds = torch.max(preds, dim= 1)\n",
    "    acc = torch.sum(preds == y) / len(y)\n",
    "    return acc\n",
    "def calculateLoss(model, batch, criterion):\n",
    "        text, text_len = batch\n",
    "        preds = model(text, text_len.to('cpu') )\n",
    "        loss = criterion(preds, batch.label)\n",
    "        acc = accuracy(preds, batch.label)\n",
    "        return loss, len(batch.label), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifier(\n",
       "  (embed): Embedding(8159, 100)\n",
       "  (lstm): LSTM(100, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected `len(lengths)` to be equal to batch_size, but got 64 (batch_size=130)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 59'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_no, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=5'>6</a>\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=6'>7</a>\u001b[0m     loss, blen, acc \u001b[39m=\u001b[39m calculateLoss( model, batch,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=7'>8</a>\u001b[0m                       criterion)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=8'>9</a>\u001b[0m     train_loss\u001b[39m.\u001b[39mappend(loss \u001b[39m*\u001b[39m blen)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000069?line=9'>10</a>\u001b[0m     train_acc\u001b[39m.\u001b[39mappend(acc \u001b[39m*\u001b[39m blen)\n",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 57'\u001b[0m in \u001b[0;36mcalculateLoss\u001b[1;34m(model, batch, criterion)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000072?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculateLoss\u001b[39m(model, batch, criterion):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000072?line=5'>6</a>\u001b[0m         text, text_len \u001b[39m=\u001b[39m batch\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000072?line=6'>7</a>\u001b[0m         preds \u001b[39m=\u001b[39m model(text, text_len\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m) )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000072?line=7'>8</a>\u001b[0m         loss \u001b[39m=\u001b[39m criterion(preds, batch\u001b[39m.\u001b[39mlabel)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000072?line=8'>9</a>\u001b[0m         acc \u001b[39m=\u001b[39m accuracy(preds, batch\u001b[39m.\u001b[39mlabel)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 55'\u001b[0m in \u001b[0;36mSentimentClassifier.forward\u001b[1;34m(self, input, actual_batch_len)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=14'>15</a>\u001b[0m hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m ,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=15'>16</a>\u001b[0m                      \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=16'>17</a>\u001b[0m cell \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros( \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=17'>18</a>\u001b[0m                     \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=18'>19</a>\u001b[0m pack_out \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mrnn\u001b[39m.\u001b[39;49mpack_padded_sequence(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=19'>20</a>\u001b[0m     embed_out, actual_batch_len,batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=20'>21</a>\u001b[0m out_lstm, (hidden, cell) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(pack_out,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=21'>22</a>\u001b[0m                                      (hidden, cell))\u001b[39m#dropout\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000066?line=22'>23</a>\u001b[0m hidden \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((hidden[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m,:,:], hidden[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:,:]),dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\utils\\rnn.py:249\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=244'>245</a>\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=245'>246</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=247'>248</a>\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=248'>249</a>\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=249'>250</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 64 (batch_size=130)"
     ]
    }
   ],
   "source": [
    "N_EPOCH = 100\n",
    "for i in range (N_EPOCH):\n",
    "    model.train()\n",
    "    train_len, train_acc, train_loss  = 0, [], []\n",
    "    for batch_no, batch in enumerate(train_dataloader):\n",
    "        opt.zero_grad()\n",
    "        loss, blen, acc = calculateLoss( model, batch,\n",
    "                          criterion)\n",
    "        train_loss.append(loss * blen)\n",
    "        train_acc.append(acc * blen)\n",
    "        train_len = train_len + blen\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    train_epoch_loss = np.sum(train_loss) / train_len\n",
    "    train_epoch_acc = np.sum( train_acc ) / train_len\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            val_results = [calculateLoss( model, batch,\n",
    "                                          criterion)\n",
    "                           for batch in val_dataloader]\n",
    "            loss, batch_len, acc = zip(*val_results)\n",
    "            epoch_loss = np.sum(np.multiply(loss, batch_len)) / np.sum(batch_len)\n",
    "            epoch_acc = np.sum(np.multiply(acc , batch_len)) / np.sum(batch_len)\n",
    "        print('epoch:{}/{} epoch_train_loss:{:.4f},epoch_train_acc:{:.4f}'\n",
    "              ' epoch_val_loss:{:.4f},epoch_val_acc:{:.4f}'.format(i+1, N_EPOCH,\n",
    "                train_epoch_loss.item(), train_epoch_acc.item(),\n",
    "                epoch_loss.item(), epoch_acc.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 71,  54,   9,  ..., 769, 306,  21],\n",
      "        [ 23,  25, 120,  ...,   2,  70,  16],\n",
      "        [  8,  28,  11,  ...,  29,   2,  30],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n",
      "<built-in method count of tuple object at 0x000002140C3BE580>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "'lengths' argument should be a 1D CPU int64 tensor, but got 0D cuda:0 Long tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 57'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=5'>6</a>\u001b[0m \u001b[39m# emb.weight.data.copy_(TEXT.vocab.vectors)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=6'>7</a>\u001b[0m emb_out \u001b[39m=\u001b[39m emb(text)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=7'>8</a>\u001b[0m pack_out \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mrnn\u001b[39m.\u001b[39;49mpack_padded_sequence(emb_out,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=8'>9</a>\u001b[0m                                              \u001b[39mlen\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=9'>10</a>\u001b[0m                                              batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=10'>11</a>\u001b[0m rnn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mRNN(EMBEDDING_DIM, \u001b[39m4\u001b[39m, batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000062?line=11'>12</a>\u001b[0m out, hidden \u001b[39m=\u001b[39m rnn(pack_out)\n",
      "File \u001b[1;32md:\\Users\\dav\\anaconda3\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\nn\\utils\\rnn.py:249\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[1;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=244'>245</a>\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=245'>246</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=247'>248</a>\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=248'>249</a>\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[0;32m    <a href='file:///d%3A/Users/dav/anaconda3/envs/pytorch-gpu/lib/site-packages/torch/nn/utils/rnn.py?line=249'>250</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 'lengths' argument should be a 1D CPU int64 tensor, but got 0D cuda:0 Long tensor"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch[0])\n",
    "    print(batch.count)\n",
    "    text, len = batch[0], len(batch)\n",
    "    emb = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "    # emb.weight.data.copy_(TEXT.vocab.vectors)\n",
    "    emb_out = emb(text)\n",
    "    pack_out = nn.utils.rnn.pack_padded_sequence(emb_out,\n",
    "                                                 len,\n",
    "                                                 batch_first=True)\n",
    "    rnn = nn.RNN(EMBEDDING_DIM, 4, batch_first=True)\n",
    "    out, hidden = rnn(pack_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 5.07M/5.07M [00:01<00:00, 4.77MB/s]\n",
      "Downloading: \"https://download.pytorch.org/models/text/xlmr.vocab.pt\" to C:\\Users\\dav/.cache\\torch\\hub\\checkpoints\\xlmr.vocab.pt\n",
      "100%|| 4.85M/4.85M [00:01<00:00, 4.31MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torchtext.transforms as T\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "padding_idx = 1\n",
    "bos_idx = 0\n",
    "eos_idx = 2\n",
    "max_seq_len = 256\n",
    "xlmr_vocab_path = r\"https://download.pytorch.org/models/text/xlmr.vocab.pt\"\n",
    "xlmr_spm_model_path = r\"https://download.pytorch.org/models/text/xlmr.sentencepiece.bpe.model\"\n",
    "\n",
    "text_transform = T.Sequential(\n",
    "    T.SentencePieceTokenizer(xlmr_spm_model_path),\n",
    "    T.VocabTransform(load_state_dict_from_url(xlmr_vocab_path)),\n",
    "    T.Truncate(max_seq_len - 2),\n",
    "    T.AddToken(token=bos_idx, begin=True),\n",
    "    T.AddToken(token=eos_idx, begin=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReviewsDataset' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\reviews_analyser\\notebooks\\3-1 - CNN.ipynb Cell 62'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000074?line=5'>6</a>\u001b[0m dev_datapipe \u001b[39m=\u001b[39m val_iter\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000074?line=7'>8</a>\u001b[0m \u001b[39m# Transform the raw dataset using non-batched API (i.e apply transformation line by line)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000074?line=8'>9</a>\u001b[0m train_datapipe \u001b[39m=\u001b[39m train_datapipe\u001b[39m.\u001b[39;49mmap(\u001b[39mlambda\u001b[39;00m x: (text_pipeline(x[\u001b[39m0\u001b[39m]), x[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000074?line=9'>10</a>\u001b[0m train_datapipe \u001b[39m=\u001b[39m train_datapipe\u001b[39m.\u001b[39mbatch(batch_size)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/reviews_analyser/notebooks/3-1%20-%20CNN.ipynb#ch0000074?line=10'>11</a>\u001b[0m train_datapipe \u001b[39m=\u001b[39m train_datapipe\u001b[39m.\u001b[39mrows2columnar([\u001b[39m\"\u001b[39m\u001b[39mtoken_ids\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ReviewsDataset' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "from torchtext.datasets import SST2\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "\n",
    "train_datapipe = train_iter\n",
    "dev_datapipe = val_iter\n",
    "\n",
    "# Transform the raw dataset using non-batched API (i.e apply transformation line by line)\n",
    "train_datapipe = train_datapipe.map(lambda x: (text_pipeline(x[0]), x[1]))\n",
    "train_datapipe = train_datapipe.batch(batch_size)\n",
    "train_datapipe = train_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
    "train_dataloader = DataLoader(train_datapipe, batch_size=None)\n",
    "\n",
    "dev_datapipe = dev_datapipe.map(lambda x: (text_pipeline(x[0]), x[1]))\n",
    "dev_datapipe = dev_datapipe.batch(batch_size)\n",
    "dev_datapipe = dev_datapipe.rows2columnar([\"token_ids\", \"target\"])\n",
    "dev_dataloader = DataLoader(dev_datapipe, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d8aee86fee2b3ba25d32dc9f725c5d414dda3463734cf4a34eb13ce0a97930c"
  },
  "kernelspec": {
   "display_name": "PyTorch 1.8 (NGC 20.11/Python 3.6 Conda) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
